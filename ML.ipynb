{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e661380c-c750-46d0-8057-ca84526159ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import  RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.base import clone as sk_clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from scipy.io import arff\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from sklearn import (pipeline, preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43e00c6d-3908-4ab1-ac4a-e67036854b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "short_names = {\n",
    "    'Age': 'Age',\n",
    "    'Height': 'Ht',\n",
    "    'Weight': 'Wt',\n",
    "    'Body Mass Index (BMI)': 'BMI',\n",
    "    'Total Body Water (TBW)': 'TBW',\n",
    "    'Extracellular Water (ECW)': 'ECW',\n",
    "    'Intracellular Water (ICW)': 'ICW',\n",
    "    'Extracellular Fluid/Total Body Water (ECF/TBW)': 'ECF/TBW',\n",
    "    'Total Body Fat Ratio (TBFR) (%)': 'TBFR',\n",
    "    'Lean Mass (LM) (%)': 'LM',\n",
    "    'Body Protein Content (Protein) (%)': 'Protein',\n",
    "    'Visceral Fat Rating (VFR)': 'VFR',\n",
    "    'Bone Mass (BM)': 'BM',\n",
    "    'Muscle Mass (MM)': 'MM',\n",
    "    'Obesity (%)': 'Obesity',\n",
    "    'Total Fat Content (TFC)': 'TFC',\n",
    "    'Visceral Fat Area (VFA)': 'VFA',\n",
    "    'Visceral Muscle Area (VMA) (Kg)': 'VMA',\n",
    "    'Hepatic Fat Accumulation (HFA)': 'HFA',\n",
    "    'Glucose': 'Glu',\n",
    "    'Total Cholesterol (TC)': 'TC',\n",
    "    'Low Density Lipoprotein (LDL)': 'LDL',\n",
    "    'High Density Lipoprotein (HDL)': 'HDL',\n",
    "    'Triglyceride': 'TG',\n",
    "    'Aspartat Aminotransferaz (AST)': 'AST',\n",
    "    'Alanin Aminotransferaz (ALT)': 'ALT',\n",
    "    'Alkaline Phosphatase (ALP)': 'ALP',\n",
    "    'Creatinine': 'Cr',\n",
    "    'Glomerular Filtration Rate (GFR)': 'GFR',\n",
    "    'C-Reactive Protein (CRP)': 'CRP',\n",
    "    'Hemoglobin (HGB)': 'HGB',\n",
    "    'Vitamin D': 'VitD'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b0ac2a-9675-4da5-b50f-576af946210e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nested_cv (\n",
    "    X, y, clf, param_grid, outer_folds=5, inner_folds=2, group_ids = False, shuffle=True,\n",
    "    njobs=-1, print_params=False, scoring='roc_auc_ovr_weighted', verbose=0, debug=False, progress_bar=True\n",
    "    ):\n",
    "    '''\n",
    "    nested cross-validation (nfolds x 2)\n",
    "    outer validation holds out test fold and \n",
    "    inner validation gets the best estimator using grid search\n",
    "    inner validation uses the outer cv's train fold (50-50 split)\n",
    "\n",
    "    params:\n",
    "    X = (standardized) features\n",
    "    y = (prepocessed) label vector\n",
    "    clf = initialized classifier\n",
    "    param_grid = grid search parameter list\n",
    "    outerFolds = outer fold count\n",
    "    innerFolds = innerfold count\n",
    "    group_ids = column contain group id of each row; folds keep groups intact\n",
    "    njobs = how many cores to use (-1 = use all cores)\n",
    "    scoring = scoring metric (string)\n",
    "    verbose = pass verbose param to inner functions\n",
    "    debug = print user-set debug messages\n",
    "    '''\n",
    "    n_classes = len(np.unique(y))\n",
    "    \n",
    "    # print(type(clf))\n",
    "    # print (n_classes)\n",
    "    \n",
    "    testPredict = []\n",
    "    Stest = []\n",
    "\n",
    "    shuffle = False if group_ids is not False else shuffle\n",
    "\n",
    "    KfoldStrategy = StratifiedKFold if group_ids is False else StratifiedGroupKFold\n",
    "        \n",
    "    outer_cv = KfoldStrategy(n_splits = outer_folds, random_state = 42 if shuffle else None, shuffle = shuffle)\n",
    "\n",
    "    outer_splits = outer_cv.split(X, y) if group_ids is False else outer_cv.split(X, y, group_ids)\n",
    "\n",
    "    \n",
    "    fold_auc = []\n",
    "    scores = []\n",
    "\n",
    "    best_params_list = []\n",
    "    fold_test_truth = []\n",
    "    feature_importances = []\n",
    "    # print('Start time', datetime.now().time())\n",
    "    \n",
    "#     kfold_progress = tqdm(outer_splits, total=outer_folds) if progress_bar else outer_splits\n",
    "#     kfold_progress = progress_bar\n",
    "\n",
    "    for k, (grid_ids, test_ids) in tqdm(enumerate(outer_splits)):\n",
    "        \n",
    "#         progress_bar and kfold_progress.set_description(f'Test Fold: {k+1}/{outer_folds}')\n",
    "        \n",
    "        # print(grid_ids.shape, test_ids.shape)\n",
    "        # Accumulating training fold data and labels\n",
    "        X_grid = X[grid_ids]\n",
    "        y_grid  = y[grid_ids]\n",
    "        \n",
    "        # Accumulating test fold data and labels\n",
    "        X_test = X[test_ids]\n",
    "        y_test = y[test_ids]\n",
    "        \n",
    "#         progress_bar and kfold_progress.set_description(f'Doing GridSearch')\n",
    "\n",
    "        inner_cv = KfoldStrategy(n_splits = inner_folds, random_state = 42 if shuffle else None, shuffle = shuffle)\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator=clf, \n",
    "                                  param_grid = param_grid, n_jobs=njobs,\n",
    "                                  scoring = scoring, cv = inner_cv, verbose=verbose)\n",
    "        \n",
    "    \n",
    "        # Training and validation\n",
    "#         progress_bar and kfold_progress.set_description(f'Fitting GridSearch')\n",
    "        if group_ids is False:\n",
    "            grid_search.fit(X_grid, y_grid)\n",
    "        else:\n",
    "            groups_grid = group_ids[grid_ids]\n",
    "            grid_search.fit(X_grid, y_grid, groups = groups_grid)\n",
    "\n",
    "#         progress_bar and kfold_progress.set_description(f'Fitted GridSearch')\n",
    "        \n",
    "        if print_params: print(grid_search.best_params_)\n",
    "        \n",
    "        best_params_list.append(grid_search.best_params_)\n",
    "        \n",
    "#         progress_bar and kfold_progress.set_description(f'Testing best estimator')\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # test with the best model found in the validation step\n",
    "        # print(X_test.shape, y_test.shape)\n",
    "        y_hat =  best_model.predict(X_test)\n",
    "        # print(X_test.shape, y_test.shape, y_hat.shape)\n",
    "        \n",
    "#         progress_bar and kfold_progress.clear_prefix()\n",
    "        \n",
    "        scores.append(best_model.score(X_test, y_test))\n",
    "        \n",
    "        fold_test_truth.append({\n",
    "            'predicted':y_hat, \n",
    "            'actual': y_test})\n",
    "        \n",
    "\n",
    "        if isinstance(clf, LogisticRegression):\n",
    "            feature_importance = abs(best_model.coef_[0])\n",
    "            feature_importances.append(feature_importance)\n",
    "            \n",
    "        else:\n",
    "            feature_importance = best_model.feature_importances_\n",
    "            feature_importances.append(feature_importance)\n",
    "    \n",
    "    return scores, fold_test_truth, best_params_list, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f3ba38-2b60-4ef8-8edc-071051c5b730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_classifiers = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression (random_state = 42, class_weight = \"balanced\", max_iter=300, solver='liblinear'),\n",
    "        'params': {\n",
    "            'C': [0.8, 0.5, 1, 5, 0.01,0.05], \n",
    "            'penalty': ['l1', 'l2']\n",
    "        },\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(n_estimators= 5,  class_weight = \"balanced\",random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': list(range(10, 120, 20))\n",
    "            },\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "        'params': {\n",
    "              \"min_samples_split\": [2, 10, 20],\n",
    "              \"max_depth\": [2, 5, 10]\n",
    "            },\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        'params': {\n",
    "            \"n_estimators\":[50, 80, 110],\n",
    "            # \"min_samples_split\": [2, 5, 10, 15, 20],\n",
    "            # \"learning_rate\":[0.1, 0.3, 1],\n",
    "            \"max_depth\": [2, 5, 10, 15]\n",
    "        },\n",
    "    },\n",
    "    'SVM Linear': {\n",
    "        'model': SVC(kernel='linear', random_state=42, class_weight = \"balanced\", probability= True),\n",
    "        'params': {\n",
    "            'C': [0.8, 0.5, 0.1, 0.05, 0.01]\n",
    "        },\n",
    "    },\n",
    "    'SVM RBF': {\n",
    "        'model': SVC(kernel='rbf', random_state=42,cache_size=20000, class_weight = \"balanced\", probability= True),\n",
    "        'params': {\n",
    "            'C': [0.8, 0.5, 0.1, 0.05, 0.01], \n",
    "            'gamma': [0.1, 0.02, 0.3, 0.5, 0.05, 0.01]\n",
    "            },\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27967fc4-6253-47e6-a710-fd1cbd6b288e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### load data from the MLP result in the \n",
    "\n",
    "ds_id = 'gallstone_female' #'gallstone_male'\n",
    "output_dir = f\"result/{ds_id}\"\n",
    "with open(f\"{output_dir}/results_epochs1000_lr0.001_batch128_None_None_weight_6432168_0.9.pkl\", \"rb\") as f1:\n",
    "    results = pickle.load(f1)\n",
    "data = results['updated_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f6c82-da4e-4e21-9f29-96666e540de6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Body Mass Index (BMI)</th>\n",
       "      <th>Total Body Water (TBW)</th>\n",
       "      <th>Extracellular Water (ECW)</th>\n",
       "      <th>Intracellular Water (ICW)</th>\n",
       "      <th>Extracellular Fluid/Total Body Water (ECF/TBW)</th>\n",
       "      <th>Total Body Fat Ratio (TBFR) (%)</th>\n",
       "      <th>Lean Mass (LM) (%)</th>\n",
       "      <th>...</th>\n",
       "      <th>High Density Lipoprotein (HDL)</th>\n",
       "      <th>Triglyceride</th>\n",
       "      <th>Aspartat Aminotransferaz (AST)</th>\n",
       "      <th>Alanin Aminotransferaz (ALT)</th>\n",
       "      <th>Alkaline Phosphatase (ALP)</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Glomerular Filtration Rate (GFR)</th>\n",
       "      <th>C-Reactive Protein (CRP)</th>\n",
       "      <th>Hemoglobin (HGB)</th>\n",
       "      <th>Vitamin D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.203623</td>\n",
       "      <td>0.463434</td>\n",
       "      <td>0.013030</td>\n",
       "      <td>-0.177270</td>\n",
       "      <td>0.456202</td>\n",
       "      <td>0.699285</td>\n",
       "      <td>0.143272</td>\n",
       "      <td>0.427253</td>\n",
       "      <td>-0.197230</td>\n",
       "      <td>0.224823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678820</td>\n",
       "      <td>-0.162090</td>\n",
       "      <td>-0.279339</td>\n",
       "      <td>-0.279526</td>\n",
       "      <td>-0.388240</td>\n",
       "      <td>-1.372057</td>\n",
       "      <td>0.564248</td>\n",
       "      <td>-0.166437</td>\n",
       "      <td>0.674406</td>\n",
       "      <td>1.071487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.230679</td>\n",
       "      <td>1.044272</td>\n",
       "      <td>1.009852</td>\n",
       "      <td>0.477763</td>\n",
       "      <td>1.081179</td>\n",
       "      <td>1.725663</td>\n",
       "      <td>0.296312</td>\n",
       "      <td>1.195360</td>\n",
       "      <td>0.735436</td>\n",
       "      <td>-0.720671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057996</td>\n",
       "      <td>0.601097</td>\n",
       "      <td>0.389652</td>\n",
       "      <td>-0.070576</td>\n",
       "      <td>-0.493211</td>\n",
       "      <td>1.294059</td>\n",
       "      <td>-1.249532</td>\n",
       "      <td>-0.375703</td>\n",
       "      <td>-0.041463</td>\n",
       "      <td>0.882816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.483730</td>\n",
       "      <td>1.189482</td>\n",
       "      <td>-0.201970</td>\n",
       "      <td>-0.640587</td>\n",
       "      <td>-0.240887</td>\n",
       "      <td>0.297659</td>\n",
       "      <td>-0.583669</td>\n",
       "      <td>0.939325</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>-0.093372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174813</td>\n",
       "      <td>-0.382566</td>\n",
       "      <td>-0.279339</td>\n",
       "      <td>0.138374</td>\n",
       "      <td>-0.283270</td>\n",
       "      <td>-0.038999</td>\n",
       "      <td>0.103390</td>\n",
       "      <td>-0.410853</td>\n",
       "      <td>0.674406</td>\n",
       "      <td>0.984054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.763836</td>\n",
       "      <td>-0.262613</td>\n",
       "      <td>1.687429</td>\n",
       "      <td>1.755877</td>\n",
       "      <td>0.360052</td>\n",
       "      <td>1.770288</td>\n",
       "      <td>-0.889750</td>\n",
       "      <td>2.475540</td>\n",
       "      <td>2.115270</td>\n",
       "      <td>-2.122029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678820</td>\n",
       "      <td>-0.450405</td>\n",
       "      <td>-0.279339</td>\n",
       "      <td>-0.488477</td>\n",
       "      <td>0.801421</td>\n",
       "      <td>-0.610310</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>-0.223658</td>\n",
       "      <td>1.310733</td>\n",
       "      <td>-0.041213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.356589</td>\n",
       "      <td>0.753853</td>\n",
       "      <td>-0.104243</td>\n",
       "      <td>-0.400940</td>\n",
       "      <td>0.912916</td>\n",
       "      <td>0.743910</td>\n",
       "      <td>0.870213</td>\n",
       "      <td>-0.084819</td>\n",
       "      <td>-0.848818</td>\n",
       "      <td>0.887188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252416</td>\n",
       "      <td>-0.111211</td>\n",
       "      <td>-1.115578</td>\n",
       "      <td>-1.219802</td>\n",
       "      <td>-0.738141</td>\n",
       "      <td>-0.610310</td>\n",
       "      <td>0.631586</td>\n",
       "      <td>-0.403496</td>\n",
       "      <td>-0.280086</td>\n",
       "      <td>0.747831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2.257736</td>\n",
       "      <td>-0.698241</td>\n",
       "      <td>0.117273</td>\n",
       "      <td>0.397881</td>\n",
       "      <td>-0.337037</td>\n",
       "      <td>-0.684094</td>\n",
       "      <td>0.105012</td>\n",
       "      <td>-0.753072</td>\n",
       "      <td>0.753323</td>\n",
       "      <td>-0.760933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174813</td>\n",
       "      <td>-0.229928</td>\n",
       "      <td>0.055156</td>\n",
       "      <td>0.138374</td>\n",
       "      <td>0.836411</td>\n",
       "      <td>4.150613</td>\n",
       "      <td>-3.086787</td>\n",
       "      <td>-0.236737</td>\n",
       "      <td>0.435783</td>\n",
       "      <td>-0.736996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.577098</td>\n",
       "      <td>0.027806</td>\n",
       "      <td>0.508183</td>\n",
       "      <td>0.461787</td>\n",
       "      <td>0.191789</td>\n",
       "      <td>-1.130345</td>\n",
       "      <td>1.252813</td>\n",
       "      <td>-2.110062</td>\n",
       "      <td>-0.014530</td>\n",
       "      <td>0.036503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174400</td>\n",
       "      <td>0.838533</td>\n",
       "      <td>-1.282826</td>\n",
       "      <td>-0.697427</td>\n",
       "      <td>-0.493211</td>\n",
       "      <td>-0.705528</td>\n",
       "      <td>0.236829</td>\n",
       "      <td>-0.446004</td>\n",
       "      <td>0.753947</td>\n",
       "      <td>-0.902659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.076483</td>\n",
       "      <td>-0.262613</td>\n",
       "      <td>-0.716669</td>\n",
       "      <td>-0.608634</td>\n",
       "      <td>-0.361075</td>\n",
       "      <td>-0.148592</td>\n",
       "      <td>-0.392369</td>\n",
       "      <td>0.171217</td>\n",
       "      <td>-0.772161</td>\n",
       "      <td>0.806666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407209</td>\n",
       "      <td>-0.687841</td>\n",
       "      <td>-0.279339</td>\n",
       "      <td>-0.175051</td>\n",
       "      <td>0.031640</td>\n",
       "      <td>-0.800747</td>\n",
       "      <td>0.953445</td>\n",
       "      <td>-0.421480</td>\n",
       "      <td>0.515324</td>\n",
       "      <td>-0.414874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.390361</td>\n",
       "      <td>-1.424289</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.621551</td>\n",
       "      <td>-0.192812</td>\n",
       "      <td>0.208409</td>\n",
       "      <td>-0.277589</td>\n",
       "      <td>0.591116</td>\n",
       "      <td>0.677943</td>\n",
       "      <td>-0.667422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019607</td>\n",
       "      <td>-0.670881</td>\n",
       "      <td>1.225890</td>\n",
       "      <td>-0.070576</td>\n",
       "      <td>-0.283270</td>\n",
       "      <td>0.722749</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>-0.446004</td>\n",
       "      <td>-1.314118</td>\n",
       "      <td>-0.746200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.137311</td>\n",
       "      <td>-0.843451</td>\n",
       "      <td>-0.723184</td>\n",
       "      <td>-0.400940</td>\n",
       "      <td>-0.889902</td>\n",
       "      <td>-0.282468</td>\n",
       "      <td>-1.119310</td>\n",
       "      <td>0.683289</td>\n",
       "      <td>-0.222782</td>\n",
       "      <td>0.248201</td>\n",
       "      <td>...</td>\n",
       "      <td>8.361925</td>\n",
       "      <td>-1.501906</td>\n",
       "      <td>1.225890</td>\n",
       "      <td>5.675552</td>\n",
       "      <td>-0.038340</td>\n",
       "      <td>1.674933</td>\n",
       "      <td>-1.838887</td>\n",
       "      <td>-0.446004</td>\n",
       "      <td>0.276701</td>\n",
       "      <td>0.809188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age    Height    Weight  Body Mass Index (BMI)  \\\n",
       "0    0.203623  0.463434  0.013030              -0.177270   \n",
       "1    1.230679  1.044272  1.009852               0.477763   \n",
       "2    0.483730  1.189482 -0.201970              -0.640587   \n",
       "4    0.763836 -0.262613  1.687429               1.755877   \n",
       "5   -0.356589  0.753853 -0.104243              -0.400940   \n",
       "..        ...       ...       ...                    ...   \n",
       "100  2.257736 -0.698241  0.117273               0.397881   \n",
       "101  0.577098  0.027806  0.508183               0.461787   \n",
       "102 -0.076483 -0.262613 -0.716669              -0.608634   \n",
       "103  0.390361 -1.424289  0.006515               0.621551   \n",
       "106  1.137311 -0.843451 -0.723184              -0.400940   \n",
       "\n",
       "     Total Body Water (TBW)  Extracellular Water (ECW)  \\\n",
       "0                  0.456202                   0.699285   \n",
       "1                  1.081179                   1.725663   \n",
       "2                 -0.240887                   0.297659   \n",
       "4                  0.360052                   1.770288   \n",
       "5                  0.912916                   0.743910   \n",
       "..                      ...                        ...   \n",
       "100               -0.337037                  -0.684094   \n",
       "101                0.191789                  -1.130345   \n",
       "102               -0.361075                  -0.148592   \n",
       "103               -0.192812                   0.208409   \n",
       "106               -0.889902                  -0.282468   \n",
       "\n",
       "     Intracellular Water (ICW)  \\\n",
       "0                     0.143272   \n",
       "1                     0.296312   \n",
       "2                    -0.583669   \n",
       "4                    -0.889750   \n",
       "5                     0.870213   \n",
       "..                         ...   \n",
       "100                   0.105012   \n",
       "101                   1.252813   \n",
       "102                  -0.392369   \n",
       "103                  -0.277589   \n",
       "106                  -1.119310   \n",
       "\n",
       "     Extracellular Fluid/Total Body Water (ECF/TBW)  \\\n",
       "0                                          0.427253   \n",
       "1                                          1.195360   \n",
       "2                                          0.939325   \n",
       "4                                          2.475540   \n",
       "5                                         -0.084819   \n",
       "..                                              ...   \n",
       "100                                       -0.753072   \n",
       "101                                       -2.110062   \n",
       "102                                        0.171217   \n",
       "103                                        0.591116   \n",
       "106                                        0.683289   \n",
       "\n",
       "     Total Body Fat Ratio (TBFR) (%)  Lean Mass (LM) (%)  ...  \\\n",
       "0                          -0.197230            0.224823  ...   \n",
       "1                           0.735436           -0.720671  ...   \n",
       "2                           0.109400           -0.093372  ...   \n",
       "4                           2.115270           -2.122029  ...   \n",
       "5                          -0.848818            0.887188  ...   \n",
       "..                               ...                 ...  ...   \n",
       "100                         0.753323           -0.760933  ...   \n",
       "101                        -0.014530            0.036503  ...   \n",
       "102                        -0.772161            0.806666  ...   \n",
       "103                         0.677943           -0.667422  ...   \n",
       "106                        -0.222782            0.248201  ...   \n",
       "\n",
       "     High Density Lipoprotein (HDL)  Triglyceride  \\\n",
       "0                         -0.678820     -0.162090   \n",
       "1                         -0.057996      0.601097   \n",
       "2                          0.174813     -0.382566   \n",
       "4                         -0.678820     -0.450405   \n",
       "5                          0.252416     -0.111211   \n",
       "..                              ...           ...   \n",
       "100                        0.174813     -0.229928   \n",
       "101                       -0.174400      0.838533   \n",
       "102                       -0.407209     -0.687841   \n",
       "103                        0.019607     -0.670881   \n",
       "106                        8.361925     -1.501906   \n",
       "\n",
       "     Aspartat Aminotransferaz (AST)  Alanin Aminotransferaz (ALT)  \\\n",
       "0                         -0.279339                     -0.279526   \n",
       "1                          0.389652                     -0.070576   \n",
       "2                         -0.279339                      0.138374   \n",
       "4                         -0.279339                     -0.488477   \n",
       "5                         -1.115578                     -1.219802   \n",
       "..                              ...                           ...   \n",
       "100                        0.055156                      0.138374   \n",
       "101                       -1.282826                     -0.697427   \n",
       "102                       -0.279339                     -0.175051   \n",
       "103                        1.225890                     -0.070576   \n",
       "106                        1.225890                      5.675552   \n",
       "\n",
       "     Alkaline Phosphatase (ALP)  Creatinine  Glomerular Filtration Rate (GFR)  \\\n",
       "0                     -0.388240   -1.372057                          0.564248   \n",
       "1                     -0.493211    1.294059                         -1.249532   \n",
       "2                     -0.283270   -0.038999                          0.103390   \n",
       "4                      0.801421   -0.610310                          0.129337   \n",
       "5                     -0.738141   -0.610310                          0.631586   \n",
       "..                          ...         ...                               ...   \n",
       "100                    0.836411    4.150613                         -3.086787   \n",
       "101                   -0.493211   -0.705528                          0.236829   \n",
       "102                    0.031640   -0.800747                          0.953445   \n",
       "103                   -0.283270    0.722749                         -0.436543   \n",
       "106                   -0.038340    1.674933                         -1.838887   \n",
       "\n",
       "     C-Reactive Protein (CRP)  Hemoglobin (HGB)  Vitamin D  \n",
       "0                   -0.166437          0.674406   1.071487  \n",
       "1                   -0.375703         -0.041463   0.882816  \n",
       "2                   -0.410853          0.674406   0.984054  \n",
       "4                   -0.223658          1.310733  -0.041213  \n",
       "5                   -0.403496         -0.280086   0.747831  \n",
       "..                        ...               ...        ...  \n",
       "100                 -0.236737          0.435783  -0.736996  \n",
       "101                 -0.446004          0.753947  -0.902659  \n",
       "102                 -0.421480          0.515324  -0.414874  \n",
       "103                 -0.446004         -1.314118  -0.746200  \n",
       "106                 -0.446004          0.276701   0.809188  \n",
       "\n",
       "[94 rows x 32 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition1 = (data['class'] == 1) & (data['mlp_acc'] < 0.5)\n",
    "condition2 = (data['class'] == 0) & (data['mlp_acc'] > 0.5)\n",
    "\n",
    "filtered_data = data[~(condition1 | condition2)]\n",
    "filtered_data.to_csv(f'{directory}/remove_wrong.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049ed0f-a199-411e-857a-4b7ac115a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = filtered_data['class']\n",
    "X = filtered_data.drop(columns = ['class', 'mlp_acc'])\n",
    "\n",
    "X = X.fillna(X.median())\n",
    "mean = X.mean(axis=0, skipna=True)\n",
    "std = X.std(axis=0, skipna=True)\n",
    "X_imp = (X - mean)/std\n",
    "X_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3451c629-59c6-4824-9829-0249b2ba5701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory = f'result/{ds_id}'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "filename_result = f'{directory}/ml_result.pkl'\n",
    "\n",
    "if os.path.exists(filename_result):\n",
    "    with open(filename_result, 'rb') as f:\n",
    "        try:\n",
    "            metrics_dict_result = pickle.load(f)\n",
    "        except EOFError:  # In case the file is empty or corrupted\n",
    "            metrics_dict_result = {'Random Forest':{}, 'Gradient Boosting':{}, 'Logistic Regression':{}}\n",
    "else:\n",
    "    metrics_dict_result = {'Random Forest':{}, 'Gradient Boosting':{}, 'Logistic Regression':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f20bcd6-a48f-4aa7-8326-7ef5a2cc8fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bd1c7ed53f4e69a8d18b4b4b2db01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all: Random Forest\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7f1a9c35ff44d49bfd12764d890745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all: Gradient Boosting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0fb69702f934e308b8165123d4ff87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "clf_list = ['Random Forest', 'Gradient Boosting', 'Logistic Regression']\n",
    "\n",
    "clf_output = {}\n",
    "for i in clf_list:\n",
    "    clf = common_classifiers[i]['model']\n",
    "    param_grid = common_classifiers[i]['params']\n",
    "\n",
    "\n",
    "    output = nested_cv (X_imp.values, y.values, clf, param_grid, outer_folds=10, inner_folds=2)\n",
    "    clf_output.update({i:output})\n",
    "    \n",
    "    a,b,c,d = output\n",
    "    result_imp = {'acc_scores':a, 'fold_test_truth':b, 'best_params_list':c, 'feature_importances':d}\n",
    "    metrics_dict_result[i] = result_imp\n",
    "    with open(filename_result, 'wb') as f:\n",
    "        pickle.dump(metrics_dict_result, f)\n",
    "    \n",
    "    print('all:',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "97df4d9a-afc7-42e5-b6e4-207ec88e4dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_importance(directory):\n",
    "    print(directory)\n",
    "    with open(f\"{directory}/ml_result.pkl\", 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    f = pd.DataFrame(data_dict['Gradient Boosting']['feature_importances']).T\n",
    "    f_lg = pd.DataFrame(data_dict['Logistic Regression']['feature_importances']).T\n",
    "\n",
    "    data_path = f'{directory}/remove_wrong.csv'\n",
    "    data = pd.read_csv(data_path)\n",
    "    correlation_with_HF = data.drop(columns = ['class']).rename(columns = short_names).corr(method='pearson')['mlp_acc'].round(2).sort_values(ascending=False)\n",
    "\n",
    "    data = data.drop(columns=['Unnamed: 0', 'mlp_acc','class'], errors='ignore')\n",
    "    f.index = data.columns\n",
    "    f_lg.index = data.columns\n",
    "    mean_imp_score = f.mean(axis=1).rename(index = short_names)#.rename(index = smoke_change)\n",
    "    mean_imp_score_lg = f_lg.mean(axis=1).rename(index = short_names)\n",
    "#     std_imp_score = f.std(axis=1).rename(index = short_names)#.rename(index = smoke_change)\n",
    "    mean_imp = f.mean(axis=1).rank(ascending=False).rename(index = short_names)\n",
    "    mean_imp_lg = f_lg.mean(axis=1).rank(ascending=False).rename(index = short_names)\n",
    "#     std_imp = f.std(axis=1)#.rank(ascending=False)\n",
    "#     print(mean_imp.sort_values().head(10))\n",
    "#     mean_imp = mean_imp.rename(index = short_names)#.rename(index = smoke_change)\n",
    "#     imp = mean_imp.sort_values()\n",
    "    return mean_imp_score, mean_imp_score_lg, correlation_with_HF#, prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c4044c4c-875b-4c14-9215-ccfc2942e2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bigger(weight_matrix):\n",
    "    \"\"\"\n",
    "    Enforces one-directional causal relationships in the weight matrix\n",
    "    while keeping the original weight values.\n",
    "\n",
    "    Parameters:\n",
    "    - weight_matrix (numpy.ndarray): The original weight matrix from NOTEARS (n x n).\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The processed weight matrix with one direction enforced.\n",
    "    \"\"\"\n",
    "    # Ensure the matrix is square\n",
    "    assert weight_matrix.shape[0] == weight_matrix.shape[1], \"Weight matrix must be square.\"\n",
    "\n",
    "    # Create a copy of the weight matrix\n",
    "    one_direction_matrix = weight_matrix.copy()\n",
    "\n",
    "    # Enforce one direction\n",
    "    for i in range(weight_matrix.shape[0]):\n",
    "        for j in range(i + 1, weight_matrix.shape[1]):  # Only process upper triangular part\n",
    "            if weight_matrix[i, j] > weight_matrix[j, i]:\n",
    "                one_direction_matrix[j, i] = 0  # Keep W[i, j] and remove W[j, i]\n",
    "            else:\n",
    "                one_direction_matrix[i, j] = 0  # Keep W[j, i] and remove W[i, j]\n",
    "\n",
    "    return one_direction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ec0987b-73d6-4fac-9dac-31a2a5f29e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imp_gbt, imp_lg, corr_f = feature_importance(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "65e106e6-4eba-45ef-9ed6-b09b7231b3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def causality_weight(model, directory, ds_id):\n",
    "    if model == 'LiNGAM':\n",
    "        w = pd.read_csv(f'{directory}/LiNGAM_mlp_acc_{ds_id}_stand.csv')#class\n",
    "#         w = pd.read_csv(f'results/causal/remove_out/{group}_LiNGAM_matrix.csv')_gbt\n",
    "        w.index = w['Unnamed: 0']\n",
    "        w = w.drop(columns = ['Unnamed: 0'])\n",
    "        effect = w['mlp_acc'][w['mlp_acc'] != 0].rename(index = short_names)#.abs().rank(ascending=False)#.sort_values()\n",
    "        cause = w.loc['mlp_acc'][w.loc['mlp_acc'] != 0].rename(index = short_names)#.abs().rank(ascending=False)#.sort_values() \n",
    "#         effect = w['mlp_label'][w['mlp_label'] != 0].abs().rename(index = short_names)#.rank(ascending=False)#.sort_values()\n",
    "#         cause = w.loc['mlp_label'][w.loc['mlp_label'] != 0].abs().rename(index = short_names)#.rank(ascending=False)#.sort_values()        \n",
    "#         effect = w['combine'][w['combine'] != 0].abs().rename(index = short_names)\n",
    "#         cause = w.loc['combine'][w.loc['combine'] != 0].abs().rename(index = short_names)\n",
    "#         effect = w['gbt_label'][w['gbt_label'] != 0].abs().rename(index = short_names)\n",
    "#         cause = w.loc['gbt_label'][w.loc['gbt_label'] != 0].abs().rename(index = short_names)\n",
    "    else:\n",
    "        # dag = pd.read_csv(f'{directory}/{model}_mlp_acc_{ds_id}_stand.csv')#_gbt_gbt\n",
    "        w = pd.read_csv(f'{directory}/{model}_mlp_acc_{ds_id}_stand_weight.csv')#class\n",
    "        # dag.index = dag['Unnamed: 0']\n",
    "        # dag = dag.drop(columns = ['Unnamed: 0'])\n",
    "        w.index = w['Unnamed: 0']\n",
    "        w = w.drop(columns = ['Unnamed: 0'])\n",
    "        w1 = bigger(w.values)\n",
    "        w1 = pd.DataFrame(w1, index= w.columns, columns = w.columns)\n",
    "    #     print(dag*w).sort_values().rank(ascending=False)\n",
    "#         cause = w[w>0.05]['combine'].drop(index = 'combine').rename(index = short_names)\n",
    "#         effect = w[w>0.05].loc['combine'].drop(index = 'combine').rename(index = short_names)\n",
    "#         cause = w[w>0.05]['gbt_label'].drop(index = 'gbt_label').rename(index = short_names)\n",
    "#         effect = w[w>0.05].loc['gbt_label'].drop(index = 'gbt_label').rename(index = short_names)\n",
    "#         cause = w[w>0.05]['mlp_label'].drop(index = 'mlp_label').rename(index = short_names)#.rank(ascending=False)#.sort_values()\n",
    "#         effect = w[w>0.05].loc['mlp_label'].drop(index = 'mlp_label').rename(index = short_names)#.rank(ascending=False)#.sort_values()\n",
    "        cause = w1[w1 > 0.01].loc['mlp_acc'].drop(index = 'mlp_acc').rename(index = short_names)#.rank(ascending=False)#.sort_values()\n",
    "        effect = w1[w1 > 0.01]['mlp_acc'].drop(index = 'mlp_acc').rename(index = short_names)\n",
    "        # cause = w1[w1 > 0.01].loc['class'].drop(index = 'class').rename(index = short_names)#.rank(ascending=False)#.sort_values()\n",
    "        # effect = w1[w1 > 0.01]['class'].drop(index = 'class').rename(index = short_names)\n",
    "    return cause, effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5152a819-3db4-48ba-89d9-5bff7cfdf901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Notearsmlp ==============================================\n",
      "result/gallstone_female\n",
      "result/gallstone_female\n",
      "result/gallstone_female\n",
      "Table for Cause\n",
      "     gallstone_female                                                     \\\n",
      "                Cause   GBT_Imp    LG_Imp F_Corr Cause_rank GBT_Imp_rank   \n",
      "Glu          0.840728  0.099596  1.224716  -0.32        4.0          3.0   \n",
      "LDL          0.285722  0.000642  0.109322  -0.05        7.0          9.0   \n",
      "HDL          0.466718  0.009126  0.330912   0.14        5.0          5.0   \n",
      "TG           0.133548  0.003225  0.083521   0.05        9.0          8.0   \n",
      "AST          0.853421  0.008860  0.666199  -0.39        2.0          6.0   \n",
      "ALT          0.247228  0.031441  0.212942  -0.04        8.0          4.0   \n",
      "CRP          0.849873  0.313556  2.042605   0.37        3.0          2.0   \n",
      "HGB          0.320761  0.005361  0.339577  -0.13        6.0          7.0   \n",
      "VitD         1.140721  0.343696  1.601538  -0.56        1.0          1.0   \n",
      "\n",
      "                              \n",
      "     LG_Imp_rank F_Corr_rank  \n",
      "Glu          3.0         4.0  \n",
      "LDL          8.0         7.0  \n",
      "HDL          6.0         5.0  \n",
      "TG           9.0         7.0  \n",
      "AST          4.0         2.0  \n",
      "ALT          7.0         9.0  \n",
      "CRP          1.0         3.0  \n",
      "HGB          5.0         6.0  \n",
      "VitD         2.0         1.0  \n",
      "\n",
      "Table for Effect\n",
      "        gallstone_female                                                      \\\n",
      "                  Effect   GBT_Imp    LG_Imp F_Corr Effect_rank GBT_Imp_rank   \n",
      "Age             0.111999  0.000008  0.557944   0.15        12.0         14.0   \n",
      "Ht              0.053301  0.002037  0.075652   0.07        13.0         10.0   \n",
      "ECW             0.340779  0.008444  0.268137  -0.18         6.0          6.0   \n",
      "ECF/TBW         0.614011  0.032669  0.706875  -0.42         1.0          1.0   \n",
      "TBFR            0.373547  0.021908  0.450094   0.32         5.0          2.0   \n",
      "Protein         0.263138  0.001367  0.712055  -0.02         7.0         11.0   \n",
      "BM              0.025854  0.000386  0.162427   0.06        14.0         12.0   \n",
      "MM              0.190803  0.000283  0.452005   0.12         9.0         13.0   \n",
      "Obesity         0.488294  0.010893  0.510872   0.05         2.0          5.0   \n",
      "TFC             0.430907  0.005000  0.140453   0.31         3.0          7.0   \n",
      "VFA             0.190329  0.003711  0.094973   0.36        10.0          9.0   \n",
      "VMA             0.416784  0.004261  0.835128   0.25         4.0          8.0   \n",
      "Cr              0.229564  0.011553  0.433920   0.23         8.0          4.0   \n",
      "GFR             0.166549  0.013353  0.536764  -0.27        11.0          3.0   \n",
      "\n",
      "                                 \n",
      "        LG_Imp_rank F_Corr_rank  \n",
      "Age             4.0         9.0  \n",
      "Ht             14.0        11.0  \n",
      "ECW            10.0         8.0  \n",
      "ECF/TBW         3.0         1.0  \n",
      "TBFR            8.0         3.0  \n",
      "Protein         2.0        14.0  \n",
      "BM             11.0        12.0  \n",
      "MM              7.0        10.0  \n",
      "Obesity         6.0        13.0  \n",
      "TFC            12.0         4.0  \n",
      "VFA            13.0         2.0  \n",
      "VMA             1.0         6.0  \n",
      "Cr              9.0         7.0  \n",
      "GFR             5.0         5.0  \n",
      "Table for Cause\n",
      "\n",
      "Table for Effect\n",
      "     gallstone_female           \n",
      "          F_Corr_rank Cause_rank\n",
      "Glu               4.0        4.0\n",
      "LDL               7.0        7.0\n",
      "HDL               5.0        5.0\n",
      "TG                7.0        9.0\n",
      "AST               2.0        2.0\n",
      "ALT               9.0        8.0\n",
      "CRP               3.0        3.0\n",
      "HGB               6.0        6.0\n",
      "VitD              1.0        1.0\n",
      "     gallstone_female           \n",
      "         GBT_Imp_rank Cause_rank\n",
      "Glu               3.0        4.0\n",
      "LDL               9.0        7.0\n",
      "HDL               5.0        5.0\n",
      "TG                8.0        9.0\n",
      "AST               6.0        2.0\n",
      "ALT               4.0        8.0\n",
      "CRP               2.0        3.0\n",
      "HGB               7.0        6.0\n",
      "VitD              1.0        1.0\n",
      "     gallstone_female           \n",
      "          LG_Imp_rank Cause_rank\n",
      "Glu               3.0        4.0\n",
      "LDL               8.0        7.0\n",
      "HDL               6.0        5.0\n",
      "TG                9.0        9.0\n",
      "AST               4.0        2.0\n",
      "ALT               7.0        8.0\n",
      "CRP               1.0        3.0\n",
      "HGB               5.0        6.0\n",
      "VitD              2.0        1.0\n",
      "======================================== LiNGAM ==============================================\n",
      "result/gallstone_female\n",
      "result/gallstone_female\n",
      "result/gallstone_female\n",
      "Table for Cause\n",
      "     gallstone_female                                                     \\\n",
      "                Cause   GBT_Imp    LG_Imp F_Corr Cause_rank GBT_Imp_rank   \n",
      "Wt          -0.699598  0.005593  0.040360   0.28        2.0          9.0   \n",
      "BMI         -0.166378  0.000453  0.062833   0.24        7.0         12.0   \n",
      "ECW         -0.072635  0.008444  0.268137  -0.18       13.0          8.0   \n",
      "ICW          0.692625  0.005186  0.366062   0.33        3.0         10.0   \n",
      "TBFR         0.885193  0.021908  0.450094   0.32        1.0          4.0   \n",
      "MM          -0.145499  0.000283  0.452005   0.12        9.0         13.0   \n",
      "VMA          0.137640  0.004261  0.835128   0.25       12.0         11.0   \n",
      "Glu         -0.288346  0.099596  1.224716  -0.32        5.0          3.0   \n",
      "HDL          0.140616  0.009126  0.330912   0.14       10.0          6.0   \n",
      "AST         -0.166017  0.008860  0.666199  -0.39        8.0          7.0   \n",
      "GFR         -0.197914  0.013353  0.536764  -0.27        6.0          5.0   \n",
      "CRP          0.137663  0.313556  2.042605   0.37       11.0          2.0   \n",
      "VitD        -0.480976  0.343696  1.601538  -0.56        4.0          1.0   \n",
      "\n",
      "                              \n",
      "     LG_Imp_rank F_Corr_rank  \n",
      "Wt          13.0         7.0  \n",
      "BMI         12.0        10.0  \n",
      "ECW         11.0        11.0  \n",
      "ICW          9.0         4.0  \n",
      "TBFR         8.0         5.0  \n",
      "MM           7.0        13.0  \n",
      "VMA          4.0         9.0  \n",
      "Glu          3.0         5.0  \n",
      "HDL         10.0        12.0  \n",
      "AST          5.0         2.0  \n",
      "GFR          6.0         8.0  \n",
      "CRP          1.0         3.0  \n",
      "VitD         2.0         1.0  \n",
      "\n",
      "Table for Effect\n",
      "Empty DataFrame\n",
      "Columns: [(gallstone_female, Effect), (gallstone_female, GBT_Imp), (gallstone_female, LG_Imp), (gallstone_female, F_Corr), (gallstone_female, Effect_rank), (gallstone_female, GBT_Imp_rank), (gallstone_female, LG_Imp_rank), (gallstone_female, F_Corr_rank)]\n",
      "Index: []\n",
      "Table for Cause\n",
      "\n",
      "Table for Effect\n",
      "     gallstone_female           \n",
      "          F_Corr_rank Cause_rank\n",
      "Wt                7.0        2.0\n",
      "BMI              10.0        7.0\n",
      "ECW              11.0       13.0\n",
      "ICW               4.0        3.0\n",
      "TBFR              5.0        1.0\n",
      "MM               13.0        9.0\n",
      "VMA               9.0       12.0\n",
      "Glu               5.0        5.0\n",
      "HDL              12.0       10.0\n",
      "AST               2.0        8.0\n",
      "GFR               8.0        6.0\n",
      "CRP               3.0       11.0\n",
      "VitD              1.0        4.0\n",
      "     gallstone_female           \n",
      "         GBT_Imp_rank Cause_rank\n",
      "Wt                9.0        2.0\n",
      "BMI              12.0        7.0\n",
      "ECW               8.0       13.0\n",
      "ICW              10.0        3.0\n",
      "TBFR              4.0        1.0\n",
      "MM               13.0        9.0\n",
      "VMA              11.0       12.0\n",
      "Glu               3.0        5.0\n",
      "HDL               6.0       10.0\n",
      "AST               7.0        8.0\n",
      "GFR               5.0        6.0\n",
      "CRP               2.0       11.0\n",
      "VitD              1.0        4.0\n",
      "     gallstone_female           \n",
      "          LG_Imp_rank Cause_rank\n",
      "Wt               13.0        2.0\n",
      "BMI              12.0        7.0\n",
      "ECW              11.0       13.0\n",
      "ICW               9.0        3.0\n",
      "TBFR              8.0        1.0\n",
      "MM                7.0        9.0\n",
      "VMA               4.0       12.0\n",
      "Glu               3.0        5.0\n",
      "HDL              10.0       10.0\n",
      "AST               5.0        8.0\n",
      "GFR               6.0        6.0\n",
      "CRP               1.0       11.0\n",
      "VitD              2.0        4.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Group</th>\n",
       "      <th>Y</th>\n",
       "      <th>X</th>\n",
       "      <th>Table Type</th>\n",
       "      <th>Pearson Corr</th>\n",
       "      <th>Pearson p-value</th>\n",
       "      <th>Spearman Corr</th>\n",
       "      <th>Spearman p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Notearsmlp</td>\n",
       "      <td>gallstone_female</td>\n",
       "      <td>Cause_rank</td>\n",
       "      <td>F_Corr_rank</td>\n",
       "      <td>Cause</td>\n",
       "      <td>0.958396</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.970720</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Notearsmlp</td>\n",
       "      <td>gallstone_female</td>\n",
       "      <td>Cause_rank</td>\n",
       "      <td>GBT_Imp_rank</td>\n",
       "      <td>Cause</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.049867</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.049867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notearsmlp</td>\n",
       "      <td>gallstone_female</td>\n",
       "      <td>Cause_rank</td>\n",
       "      <td>LG_Imp_rank</td>\n",
       "      <td>Cause</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.001591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LiNGAM</td>\n",
       "      <td>gallstone_female</td>\n",
       "      <td>Cause_rank</td>\n",
       "      <td>F_Corr_rank</td>\n",
       "      <td>Cause</td>\n",
       "      <td>0.463327</td>\n",
       "      <td>0.110809</td>\n",
       "      <td>0.445668</td>\n",
       "      <td>0.126938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LiNGAM</td>\n",
       "      <td>gallstone_female</td>\n",
       "      <td>Cause_rank</td>\n",
       "      <td>GBT_Imp_rank</td>\n",
       "      <td>Cause</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.482054</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.482054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LiNGAM</td>\n",
       "      <td>gallstone_female</td>\n",
       "      <td>Cause_rank</td>\n",
       "      <td>LG_Imp_rank</td>\n",
       "      <td>Cause</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>0.615799</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>0.615799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model             Group           Y             X Table Type  \\\n",
       "0  Notearsmlp  gallstone_female  Cause_rank   F_Corr_rank      Cause   \n",
       "1  Notearsmlp  gallstone_female  Cause_rank  GBT_Imp_rank      Cause   \n",
       "2  Notearsmlp  gallstone_female  Cause_rank   LG_Imp_rank      Cause   \n",
       "3      LiNGAM  gallstone_female  Cause_rank   F_Corr_rank      Cause   \n",
       "4      LiNGAM  gallstone_female  Cause_rank  GBT_Imp_rank      Cause   \n",
       "5      LiNGAM  gallstone_female  Cause_rank   LG_Imp_rank      Cause   \n",
       "\n",
       "   Pearson Corr  Pearson p-value  Spearman Corr  Spearman p-value  \n",
       "0      0.958396         0.000046       0.970720          0.000014  \n",
       "1      0.666667         0.049867       0.666667          0.049867  \n",
       "2      0.883333         0.001591       0.883333          0.001591  \n",
       "3      0.463327         0.110809       0.445668          0.126938  \n",
       "4      0.214286         0.482054       0.214286          0.482054  \n",
       "5     -0.153846         0.615799      -0.153846          0.615799  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = [ds_id]  # ['female', 'male_old', 'female_old', 'male_young', 'female_young']\n",
    "corr_results = []\n",
    "model = ['Notearsmlp', 'LiNGAM']\n",
    "directory = f'result/{ds_id}'\n",
    "for i in model:\n",
    "    print('========================================', i, '==============================================')\n",
    "    tables_cause = []\n",
    "    tables_effect = []\n",
    "    \n",
    "    for group in groups:\n",
    "        # Extract causality and feature importance\n",
    "        print(directory)\n",
    "        cause, effect = causality_weight(i, directory, ds_id)\n",
    "        print(directory)\n",
    "        imp_gbt, imp_lg, corr = feature_importance(directory)\n",
    "        # corr = get_corr(group)\n",
    "        \n",
    "        # scaler = MinMaxScaler()\n",
    "        \n",
    "        # Table for Cause\n",
    "        table_cause = pd.concat([cause, imp_gbt, imp_lg, corr], axis=1)#.rank(method='min', ascending=False)\n",
    "        table_cause.columns = ['Cause', 'GBT_Imp', 'LG_Imp', 'F_Corr']\n",
    "#         table_cause['LG_Imp'] = = table_cause['LG_Imp'] / table_cause['LG_Imp'].sum()\n",
    "#         print(table_cause['LG_Imp'])\n",
    "        table_cause = table_cause.dropna()\n",
    "        table_cause['Cause_rank'] = table_cause['Cause'].abs().rank(ascending=False)\n",
    "        table_cause['GBT_Imp_rank'] = table_cause['GBT_Imp'].rank(ascending=False)\n",
    "        table_cause['LG_Imp_rank'] = table_cause['LG_Imp'].abs().rank(ascending=False)\n",
    "        table_cause['F_Corr_rank'] = table_cause['F_Corr'].abs().rank(method='min', ascending=False)\n",
    "#         table_cause['S_diff(C-GBT_Imp)'] = (table_cause['Cause'] - table_cause['GBT_Imp']) ** 2\n",
    "#         table_cause['S_diff(C-LG_Imp)'] = (table_cause['Cause'] - table_cause['LG_Imp']) ** 2\n",
    "        table_cause.columns = pd.MultiIndex.from_product([[group], table_cause.columns])\n",
    "        tables_cause.append(table_cause)\n",
    "        \n",
    "        # Table for Effect\n",
    "        table_effect = pd.concat([effect, imp_gbt, imp_lg, corr], axis=1)#.rank(method='min', ascending=False)\n",
    "        table_effect.columns = ['Effect', 'GBT_Imp', 'LG_Imp', 'F_Corr']\n",
    "#         table_effect['LG_Imp'] = table_effect['LG_Imp']\n",
    "        table_effect = table_effect.dropna()\n",
    "        table_effect['Effect_rank'] = table_effect['Effect'].abs().rank(ascending=False)\n",
    "        table_effect['GBT_Imp_rank'] = table_effect['GBT_Imp'].rank(ascending=False)\n",
    "        table_effect['LG_Imp_rank'] = table_effect['LG_Imp'].abs().rank(ascending=False)\n",
    "        table_effect['F_Corr_rank'] = table_effect['F_Corr'].abs().rank(method='min', ascending=False)\n",
    "#         table_effect['S_diff(E-GBT_Imp)'] = (table_effect['Effect'] - table_effect['GBT_Imp']) ** 2\n",
    "#         table_effect['S_diff(E-LG_Imp)'] = (table_effect['Effect'] - table_effect['LG_Imp']) ** 2\n",
    "        table_effect.columns = pd.MultiIndex.from_product([[group], table_effect.columns])\n",
    "        tables_effect.append(table_effect)\n",
    "    \n",
    "    # Combine tables\n",
    "    final_table_cause = pd.concat(tables_cause, axis=1)\n",
    "    final_table_effect = pd.concat(tables_effect, axis=1)\n",
    "    \n",
    "    final_table_cause.to_csv(f'{directory}/{i}_cause_table.csv')\n",
    "    final_table_effect.to_csv(f'{directory}/{i}_effect_table.csv')\n",
    "    \n",
    "    print(\"Table for Cause\")\n",
    "    print(final_table_cause.dropna())#.astype('int')\n",
    "    print(\"\\nTable for Effect\")\n",
    "    print(final_table_effect.dropna())#.astype('int')\n",
    "    \n",
    "    print(\"Table for Cause\")\n",
    "    # print(final_table_cause.dropna()['male'][['Cause_rank', 'GBT_Imp_rank', 'LG_Imp_rank', 'F_Corr_rank']].astype('int'))\n",
    "    print(\"\\nTable for Effect\")\n",
    "    # print(final_table_effect.dropna()['male'][['Effect_rank', 'GBT_Imp_rank', 'LG_Imp_rank', 'F_Corr_rank']].astype('int'))\n",
    "    \n",
    "#     print(\"\\nLatex for Cause Table\")\n",
    "#     print(latex_table(final_table_cause.dropna().astype('int')))\n",
    "#     print(\"\\nLatex for Effect Table\")\n",
    "#     print(latex_table(final_table_effect.dropna().astype('int')))\n",
    "    \n",
    "    # Compute correlations for both tables\n",
    "    relationships = [\n",
    "#         ('Cause', 'F_Corr'), \n",
    "        ('Cause_rank', 'F_Corr_rank'),\n",
    "#         ('F_Corr', 'GBT_Imp'), \n",
    "        ('Cause_rank', 'GBT_Imp_rank'),\n",
    "        ('Cause_rank', 'LG_Imp_rank'),\n",
    "#         ('F_Corr', 'LG_Imp'), \n",
    "#         ('Cause', 'LG_Imp'),\n",
    "#         ('Effect', 'F_Corr'),\n",
    "        ('Effect_rank', 'F_Corr_rank'),\n",
    "        ('Effect_rank', 'GBT_Imp_rank'),\n",
    "        ('Effect_rank', 'LG_Imp_rank'),\n",
    "#         ('Effect', 'GBT_Imp'), ('Effect', 'LG_Imp')\n",
    "    ]\n",
    "    \n",
    "    for group in groups:\n",
    "        for y_col, x_col in relationships:\n",
    "            \n",
    "            if (group, x_col) in final_table_cause.columns and (group, y_col) in final_table_cause.columns:\n",
    "                x = final_table_cause[(group, x_col)].astype(float)\n",
    "                y = final_table_cause[(group, y_col)].astype(float)\n",
    "                xy = pd.concat([x, y], axis=1).dropna()\n",
    "#                 print(xy)\n",
    "#                 xy['F_Corr_rank'] = xy[(group,'F_Corr')].abs().rank(method='min', ascending=False)\n",
    "#                 xy['Cause_rank'] = y.abs().rank(ascending=False)\n",
    "                print(xy)\n",
    "                pearson_corr, pearson_p = pearsonr(xy[(group, y_col)], xy[(group, x_col)])\n",
    "                spearman_corr, spearman_p = spearmanr(xy[(group, y_col)], xy[(group, x_col)], nan_policy='omit')\n",
    "                corr_results.append([i, group, y_col, x_col, 'Cause', pearson_corr, pearson_p, spearman_corr, spearman_p])\n",
    "                \n",
    "#                 plt.figure(figsize=(8, 6))\n",
    "#                 sns.regplot(x=x, y=y, ci=None, color = 'black', line_kws={\"color\": \"black\"})\n",
    "                \n",
    "# #                 print(x.index)\n",
    "#                 for idx, txt in enumerate(x.index):\n",
    "#                     plt.annotate(txt, (x.iloc[idx], y.iloc[idx] - 0.5), fontsize=12, color=\"black\", alpha=0.7)\n",
    "                \n",
    "#                 # Set labels and title\n",
    "#                 plt.xlabel(x_col, fontsize=13)\n",
    "#                 plt.ylabel(y_col, fontsize=13)\n",
    "#                 plt.xticks(fontsize=13)\n",
    "#                 plt.yticks(fontsize=13)\n",
    "# #                 plt.title(f'{group}: {x_col} vs {y_col}')\n",
    "                \n",
    "#                 # Display the correlation coefficient on the plot\n",
    "#                 plt.text(0.05, 0.9, f'Spearman_corr: {spearman_corr:.2f}', transform=plt.gca().transAxes, fontsize=12, color=\"black\")\n",
    "#                 plt.tight_layout()\n",
    "#                 plt.savefig(f'results/causal/figure_2/hf_icd_male_class_corr_{x_col} vs {y_col}_{i}_{group}_cause.pdf')\n",
    "#                 plt.show()\n",
    "                \n",
    "#             if (group, x_col) in final_table_effect.columns and (group, y_col) in final_table_effect.columns:\n",
    "#                 x = final_table_effect[(group, x_col)].astype(float)\n",
    "#                 y = final_table_effect[(group, y_col)].astype(float)\n",
    "#                 xy = pd.concat([x, y], axis=1).dropna()\n",
    "# #                 xy['F_Corr_rank'] = xy[(group,'F_Corr')].abs().rank(method='min', ascending=False)\n",
    "# #                 xy['Effect_rank'] = y.abs().rank(ascending=False)\n",
    "# #                 print(xy)\n",
    "#                 pearson_corr, pearson_p = pearsonr(xy[(group, y_col)], xy[(group, x_col)])\n",
    "#                 spearman_corr, spearman_p = spearmanr(xy[(group, y_col)], xy[(group, x_col)], nan_policy='omit')\n",
    "#                 corr_results.append([i, group, y_col, x_col, 'Effect', pearson_corr, pearson_p, spearman_corr, spearman_p])\n",
    "                \n",
    "# #                 plt.figure(figsize=(8, 6))\n",
    "# #                 sns.regplot(x=x, y=y, ci=None,color = 'black', line_kws={\"color\": \"black\"})\n",
    "                \n",
    "# #                 # Add feature names beside the nodes\n",
    "# #                 for idx, txt in enumerate(x.index):\n",
    "# #                     plt.annotate(txt, (x.iloc[idx], y.iloc[idx] - 0.5), fontsize=12, color=\"black\", alpha=0.7)\n",
    "                \n",
    "# #                 # Set labels and title\n",
    "# #                 plt.xlabel(x_col, fontsize=13)\n",
    "# #                 plt.ylabel(y_col, fontsize=13)\n",
    "# #                 plt.xticks(fontsize=13)\n",
    "# #                 plt.yticks(fontsize=13)\n",
    "# # #                 plt.title(f'{group}: {x_col} vs {y_col}')\n",
    "                \n",
    "# #                 # Display the correlation coefficient on the plot\n",
    "# #                 plt.text(0.05, 0.9, f'Spearman_corr: {spearman_corr:.2f}', transform=plt.gca().transAxes, fontsize=12, color=\"black\")\n",
    "# #                 plt.tight_layout()\n",
    "# #                 plt.savefig(f'results/causal/figure_2/hf_icd_male_class_corr_{x_col} vs {y_col}_{i}_{group}_effect.pdf')\n",
    "# #                 plt.show()\n",
    "\n",
    "# Convert results to DataFrame\n",
    "corr_df = pd.DataFrame(corr_results, columns=['Model', 'Group', 'Y', 'X', 'Table Type', 'Pearson Corr', 'Pearson p-value', 'Spearman Corr', 'Spearman p-value'])\n",
    "corr_df.to_csv(f'{directory}/corrlation_table.csv')\n",
    "corr_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:functorch_cud11]",
   "language": "python",
   "name": "conda-env-functorch_cud11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
